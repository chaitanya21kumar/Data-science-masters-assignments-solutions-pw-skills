{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7460fd11-ba44-4bde-bce9-93af740d3f95",
   "metadata": {},
   "source": [
    "## Question 1 : What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bb10f6-e3eb-4c6a-9b99-82b0ac0b6a24",
   "metadata": {},
   "source": [
    "Probability Mass Function (PMF) and Probability Density Function (PDF) are both mathematical functions used to describe the probability distribution of a random variable.\n",
    "\n",
    "Probability Mass Function (PMF):\n",
    "The PMF is applicable to discrete random variables. It gives the probability of each possible outcome occurring. The PMF assigns a probability value to each specific value of the random variable.\n",
    "Example: Consider rolling a fair six-sided die. The PMF for this scenario would assign a probability value of 1/6 to each outcome (1, 2, 3, 4, 5, or 6) because each face of the die has an equal chance of occurring.\n",
    "\n",
    "Probability Density Function (PDF):\n",
    "The PDF is used for continuous random variables. It represents the likelihood of a random variable falling within a specific range of values. Unlike the PMF, the PDF does not give the probability of individual values; instead, it provides the relative likelihood of values within a range.\n",
    "Example: Suppose we have a continuous random variable that represents the height of individuals in a population. The PDF for this variable would describe the likelihood of finding individuals within a specific height range. For instance, it might indicate that the probability density is higher for heights between 160 cm and 170 cm, suggesting that individuals within that range are more likely to be found in the population.\n",
    "\n",
    "In summary, the PMF is used for discrete random variables, providing the probability of each individual outcome. The PDF is used for continuous random variables, describing the likelihood of values falling within specific ranges.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff85c5c9-9ebc-4dc0-8e32-ff675639ec5c",
   "metadata": {},
   "source": [
    "## Question 2 : What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ff13ef-92e9-4cd1-a7ac-fc6c20ea99fd",
   "metadata": {},
   "source": [
    "The Cumulative Density Function (CDF) is a mathematical function that gives the probability that a random variable takes on a value less than or equal to a given value. It provides cumulative information about the probability distribution.\n",
    "\n",
    "Example: Let's consider a continuous random variable representing the time it takes for a customer to complete a task at a service center. The CDF for this variable would give the probability that a customer's task time is less than or equal to a specific value.\n",
    "\n",
    "Suppose the CDF at time t=5 minutes is 0.8. This means that there is an 80% probability that a customer's task time is less than or equal to 5 minutes. The CDF can be interpreted as the area under the probability density curve up to a given value.\n",
    "\n",
    "The CDF is used for several reasons:\n",
    "\n",
    "Probability calculation: The CDF allows us to calculate the probability of a random variable falling within a certain range by subtracting the CDF values at the lower and upper limits of the range.\n",
    "\n",
    "Percentile determination: The CDF helps determine percentiles or quantiles of a distribution. For example, the value of the random variable at which the CDF reaches 0.5 represents the median.\n",
    "\n",
    "Distribution comparison: CDFs can be used to compare and analyze different probability distributions. By plotting multiple CDFs on the same graph, we can visually assess differences in their shapes, locations of percentiles, or probabilities at specific values.\n",
    "\n",
    "Estimation of parameters: CDFs are employed in statistical estimation techniques, such as maximum likelihood estimation, to estimate the parameters of a distribution that best fit observed data.\n",
    "\n",
    "In summary, the Cumulative Density Function (CDF) provides cumulative information about the probability distribution of a random variable, giving the probability that the variable takes on a value less than or equal to a given value. It is useful for probability calculations, percentile determination, distribution comparison, and parameter estimation.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347cf61e-eb0e-4070-922e-30ce603ef479",
   "metadata": {},
   "source": [
    "## Question 3 : What are some examples of situations where the normal distribution might be used as a model? Explain how the parameters of the normal distribution relate to the shape of the distribution.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f3ce08-f2f3-4b2d-af06-60f532e82b9b",
   "metadata": {},
   "source": [
    "The normal distribution, also known as the Gaussian distribution, is widely used as a model in various fields where data tend to exhibit a bell-shaped pattern. Some examples of situations where the normal distribution might be used as a model include:\n",
    "\n",
    "Heights and weights: In many populations, the distribution of heights and weights often follows a normal distribution.\n",
    "\n",
    "Test scores: When analyzing test scores of a large group of individuals, the normal distribution is often assumed as a reasonable approximation.\n",
    "\n",
    "Errors in measurement: Random errors in measurements, such as in scientific experiments or data collection, are often assumed to be normally distributed.\n",
    "\n",
    "Financial markets: Changes in stock prices or returns on investments are commonly modeled using the normal distribution.\n",
    "\n",
    "The normal distribution is characterized by two parameters: mean (μ) and standard deviation (σ).\n",
    "\n",
    "The mean (μ) represents the central tendency of the distribution and indicates where the peak of the bell-shaped curve is located.\n",
    "The standard deviation (σ) determines the spread or dispersion of the distribution. A larger standard deviation results in a wider and flatter curve, indicating greater variability in the data.\n",
    "By adjusting the mean and standard deviation, the shape, location, and scale of the normal distribution can be modified. The mean shifts the distribution horizontally, while the standard deviation controls its spread. Changes in these parameters can create distributions that are more peaked or flatter, narrower or wider, and shifted to the left or right.\n",
    "\n",
    "In summary, the normal distribution is often used as a model in situations where data exhibit a bell-shaped pattern. The mean parameter determines the center of the distribution, while the standard deviation parameter influences the spread. Adjusting these parameters allows for modeling different variations of the normal distribution to fit specific data patterns.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9016f9a-2958-4282-b195-87fb6941b4b2",
   "metadata": {},
   "source": [
    "## Question 4 : Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6133e1a-b8a4-432f-ad30-c33b0fb0f9f8",
   "metadata": {},
   "source": [
    "The Normal Distribution, also known as the Gaussian distribution, holds significant importance in statistics and data analysis due to its widespread applicability and several key properties. Some of the reasons why the Normal Distribution is important are:\n",
    "\n",
    "Central Limit Theorem: The Normal Distribution is a fundamental concept in the Central Limit Theorem, which states that the sum or average of a large number of independent and identically distributed random variables tends to follow a Normal Distribution, regardless of the underlying distribution of the variables themselves. This theorem allows for powerful statistical inference and estimation techniques.\n",
    "\n",
    "Data Modeling: Many real-life phenomena naturally follow a Normal Distribution. Examples include physical measurements like height and weight of individuals in a population, errors in measurements, test scores, and financial market returns. By assuming a Normal Distribution, we can simplify the modeling process and make predictions or draw inferences from the data.\n",
    "\n",
    "Statistical Analysis: The Normal Distribution provides a solid foundation for various statistical methods and hypothesis testing. Numerous statistical techniques, such as Z-tests, t-tests, and chi-square tests, rely on the assumptions of Normality to draw accurate conclusions from data.\n",
    "\n",
    "Parameter Estimation: In many statistical models, estimating the parameters of a distribution is a crucial step. The Normal Distribution is often used as a reference or default distribution for estimation procedures, such as maximum likelihood estimation and least squares regression, due to its mathematical properties and simplicity.\n",
    "\n",
    "Real-life examples of phenomena that can be modeled by the Normal Distribution include:\n",
    "\n",
    "Heights and weights of individuals in a population.\n",
    "IQ scores of a large sample of people.\n",
    "Errors in scientific measurements or experimental data.\n",
    "Blood pressure readings in a population.\n",
    "Test scores in a standardized exam.\n",
    "Time taken to complete a task by a group of people.\n",
    "In summary, the Normal Distribution is important due to its applicability in various fields, its role in the Central Limit Theorem, and its usefulness in data modeling, statistical analysis, and parameter estimation. It is encountered in numerous real-life examples where data exhibit a bell-shaped pattern, allowing for effective analysis and inference.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f7dded-1537-42df-ad85-89456e79b0fb",
   "metadata": {},
   "source": [
    "## Question 5 : What is Bernoulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c9f794-db03-4eb4-80f2-43d6330f55a1",
   "metadata": {},
   "source": [
    "A Bernoulli distribution is a discrete probability distribution that describes the outcome of a single trial of an experiment with two possible outcomes, often referred to as \"success\" and \"failure\". The probability of success is denoted by p and the probability of failure is denoted by q, where q = 1 - p.\n",
    "\n",
    "The probability mass function (pmf) of a Bernoulli distribution is given by:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2315ea0c-07e3-426f-abc1-c2adf332918f",
   "metadata": {},
   "source": [
    "f(x) = p^x(1-p)^(1-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f172365-9c28-471d-a588-a7c75614fc31",
   "metadata": {},
   "source": [
    "\n",
    "Sure. Here is a brief explanation of Bernoulli Distribution:\n",
    "\n",
    "A Bernoulli distribution is a discrete probability distribution that describes the outcome of a single trial of an experiment with two possible outcomes, often referred to as \"success\" and \"failure\". The probability of success is denoted by p and the probability of failure is denoted by q, where q = 1 - p.\n",
    "\n",
    "The probability mass function (pmf) of a Bernoulli distribution is given by:\n",
    "\n",
    "Code snippet\n",
    "f(x) = p^x(1-p)^(1-x)\n",
    "Use code with caution. Learn more\n",
    "where x is the outcome of the trial, which can be either 0 or 1.\n",
    "\n",
    "For example, if we flip a coin, the outcome of the flip is a Bernoulli random variable. The probability of getting heads is p and the probability of getting tails is q. If we assume that the coin is fair, then p = q = 0.5.\n",
    "\n",
    "The Bernoulli distribution is a special case of the binomial distribution, which describes the outcome of n independent trials of an experiment with two possible outcomes. The binomial distribution is a more general distribution than the Bernoulli distribution, but it can be difficult to calculate the probability of a particular outcome for a binomial distribution with a large number of trials.\n",
    "\n",
    "The main difference between the Bernoulli distribution and the binomial distribution is that the Bernoulli distribution only considers a single trial, while the binomial distribution considers multiple trials.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1b28a6-f2d5-4e01-ba66-e9f1cbc2c7a7",
   "metadata": {},
   "source": [
    "# Differences in Bernoulli and Binomial Distribution are as below :\n",
    "\n",
    "|          | Bernoulli distribution | Binomial distribution |\n",
    "|----------|-----------------------|-----------------------|\n",
    "| Outcome  | Single trial          | Multiple trials        |\n",
    "| Parameters | $p$ (probability of success) | $n$ (number of trials) and $p$ (probability of success in each trial) |\n",
    "| Random variable | $X = 1$ (success) or $X = 0$ (failure) | $X$ = number of successes in $n$ trials |\n",
    "| Probability mass function (PMF) | $P(X = x) = p^x \\cdot (1-p)^{1-x}$, for $x = 0$ or $x = 1$ | $P(X = k) = {n \\choose k} \\cdot p^k \\cdot (1-p)^{n-k}$, for $k = 0, 1, 2, \\ldots, n$ |\n",
    "| Mean | $E(X) = p$ | $E(X) = np$ |\n",
    "| Variance | $\\operatorname{Var}(X) = p(1-p)$ | $\\operatorname{Var}(X) = np(1-p)$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e823b0ff-4aad-45cc-b36f-87caa0de8a2c",
   "metadata": {},
   "source": [
    "## Question 6 : Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63347934-a0b2-4e2e-9f1e-49b83bd3ff4c",
   "metadata": {},
   "source": [
    "The probability that a randomly selected observation from a dataset with a mean of 50 and a standard deviation of 10 will be greater than 60 can be calculated using the following formula:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a45e5a7-bf96-4ec0-b779-032c1e8b6529",
   "metadata": {},
   "source": [
    "P(X > 60) = 1 - P(X <= 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cab77d-7d73-4505-9d9c-e332f1d881fe",
   "metadata": {},
   "source": [
    "The probability that a randomly selected observation will be less than or equal to 60 can be calculated using the normal distribution table. The normal distribution table gives the probability that a standard normal variable will be less than or equal to a certain value. A standard normal variable has a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "To use the normal distribution table, we first need to convert our observation of 60 to a standard normal variable. This can be done using the following formula:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902e85ca-fbfb-4895-bd65-4165b663a9d3",
   "metadata": {},
   "source": [
    "Z = (X - μ) / σ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf7e1e8-84ef-4f21-900e-ca9038113482",
   "metadata": {},
   "source": [
    "where:\n",
    "\n",
    "Z is the standard normal variable\n",
    "X is the observation\n",
    "μ is the mean of the dataset\n",
    "σ is the standard deviation of the dataset\n",
    "In this case, Z = (60 - 50) / 10 = 1.00.\n",
    "\n",
    "Now that we have converted our observation to a standard normal variable, we can look up the probability of a standard normal variable being less than or equal to 1.00 in the normal distribution table. The probability that a standard normal variable will be less than or equal to 1.00 is 0.8413.\n",
    "\n",
    "Therefore, the probability that a randomly selected observation from a dataset with a mean of 50 and a standard deviation of 10 will be greater than 60 is 1 - 0.8413 = 0.1587.\n",
    "\n",
    "In other words, there is a 15.87% chance that a randomly selected observation from this dataset will be greater than 60.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1448d998-91ba-4f92-823c-168eca6e3317",
   "metadata": {},
   "source": [
    "## Question 7 : Explain uniform Distribution with an example.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f79a3b9-f45d-43cc-8640-1e008d487b08",
   "metadata": {},
   "source": [
    "A uniform distribution is a probability distribution in which all outcomes are equally likely. This means that the probability of any outcome is the same, regardless of its value.\n",
    "\n",
    "One example of a uniform distribution is the distribution of values obtained in tossing a fair die. When you toss a fair die, there are six possible outcomes: 1, 2, 3, 4, 5, and 6. Each of these outcomes is equally likely, so the probability of getting any one of them is 1/6.\n",
    "\n",
    "Another example of a uniform distribution is the distribution of times it takes to complete a task. If the task is truly random, then each possible time to complete it is equally likely. For example, if it takes you an average of 10 minutes to complete a task, then the probability of finishing it in 9 minutes is the same as the probability of finishing it in 11 minutes.\n",
    "\n",
    "Uniform distributions are often used in statistical analysis. For example, you might use a uniform distribution to generate a random sample of data. This can be useful for testing hypotheses or for estimating population parameters.\n",
    "\n",
    "Here is a graph of a uniform distribution:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71195be-10f1-4b8d-bba9-0bc288952e18",
   "metadata": {},
   "source": [
    "![Uniform Distribution](https://analystprep.com/cfa-level-1-exam/wp-content/uploads/2021/09/cfa-level-1-continuous-uniform-random-variable-1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bb5aee-5d2e-4b60-a434-956edc4f723e",
   "metadata": {},
   "source": [
    "The graph shows that all values between the minimum and maximum values are equally likely. In this case, the minimum value is 0 and the maximum value is 1. The probability of any value between 0 and 1 is therefore 1/(1-0) = 1.\n",
    "\n",
    "Uniform distributions are a simple and versatile tool that can be used in a variety of statistical applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322a1940-252d-4ff2-937f-cdeb89eda0a3",
   "metadata": {},
   "source": [
    "## Question 8 : What is the Z score? State the importance of the Z score.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32637d57-1f2a-4b0a-9d75-1dea33c1f90e",
   "metadata": {},
   "source": [
    "A z-score is a statistical measure that tells you how many standard deviations a specific data point is away from the mean. A z-score is calculated by subtracting the mean from the data point and then dividing by the standard deviation.\n",
    "\n",
    "Z-scores are important because they allow you to compare data points from different distributions. For example, if you have a set of data on the heights of people in the United States and a set of data on the heights of people in China, you can't directly compare the heights of people in the two groups because the distributions of heights are different. However, if you convert the heights of people in each group to z-scores, you can then compare the z-scores directly.\n",
    "\n",
    "Z-scores are also used to determine how likely it is that a specific data point will occur. For example, if you know that the z-score for a certain height is 2.0, you can use a z-table to find out that the probability of a person being that height or taller is 97.7%.\n",
    "\n",
    "Here is the formula for calculating a z-score :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff3b92d-5bf6-44d5-82b8-4faf48f7091a",
   "metadata": {},
   "source": [
    "z = (x - μ) / σ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138592b-a548-4266-8ecc-eefc7f71f042",
   "metadata": {},
   "source": [
    "where:\n",
    "\n",
    "z is the z-score\n",
    "x is the data point\n",
    "μ is the mean of the distribution\n",
    "σ is the standard deviation of the distribution\n",
    "Here is an example of how to calculate a z-score:\n",
    "\n",
    "Suppose you have a set of data on the heights of people in the United States. The mean height is 68 inches and the standard deviation is 3 inches. If you have a data point of 72 inches, the z-score would be calculated as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7576ad-a812-4e9e-af9c-59d0a378b3ce",
   "metadata": {},
   "source": [
    "z = (72 - 68) / 3 = 1.33\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e98b1e9-23d0-4e32-984d-41c88f6d1a9f",
   "metadata": {},
   "source": [
    "This means that the data point of 72 inches is 1.33 standard deviations above the mean.\n",
    "\n",
    "Z-scores are a powerful tool that can be used to compare data points from different distributions and to determine the likelihood of a specific data point occurring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f2ac19-2f4d-4c4d-989f-7349f0a3293b",
   "metadata": {},
   "source": [
    "![](https://i.ytimg.com/vi/Zoi15vIgDQ8/maxresdefault.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444e25b4-b2dd-423d-8e62-d0d720e2d8da",
   "metadata": {},
   "source": [
    "## Question 9 : What is Central Limit Theorem? State the significance of the Central Limit Theorem.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077dae79-af7c-478e-add8-933263f85bc2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The central limit theorem (CLT) is a theorem in probability theory that states that, given certain conditions, the arithmetic mean of a sufficiently large number of iterates of independent random variables, each with a well-defined expected value and well-defined variance, will be approximately normally distributed, regardless of the underlying distribution.\n",
    "\n",
    "The CLT is a fundamental theorem in statistics and has wide-ranging applications. It is used in hypothesis testing, confidence interval estimation, and regression analysis.\n",
    "\n",
    "The CLT is based on the idea that the average of a large number of random variables will be closer to the population mean than any individual random variable. This is because the average of a large number of random variables will tend to cancel out the effects of any outliers or extreme values.\n",
    "\n",
    "The CLT also states that the standard deviation of the average of a large number of random variables will be smaller than the standard deviation of any individual random variable. This is because the average of a large number of random variables will tend to smooth out the fluctuations in the individual random variables.\n",
    "\n",
    "The CLT is a powerful tool that can be used to make inferences about populations based on samples. For example, if you want to know the average height of all people in the United States, you could take a random sample of people and calculate the average height of the sample. If the sample is large enough, the CLT tells you that the average height of the sample will be approximately normally distributed. This means that you can use a z-table to find the probability that the average height of the sample is within a certain range of the population mean.\n",
    "\n",
    "The CLT is also used in many other areas of statistics, such as hypothesis testing, confidence intervals, and regression analysis.\n",
    "\n",
    "Here are some of the significance of the Central Limit Theorem:\n",
    "\n",
    "It allows us to make inferences about populations based on samples.\n",
    "It can be used to calculate probabilities of events occurring.\n",
    "It can be used to estimate population parameters.\n",
    "It is used in many different areas of statistics, such as hypothesis testing, confidence intervals, and regression analysis.\n",
    "The CLT is a powerful tool that can be used to make sense of data. It is essential for understanding many statistical concepts and techniques.\n",
    "\n",
    "Here are some examples of how the CLT is used in practice:\n",
    "\n",
    "In hypothesis testing, the CLT is used to calculate the p-value of a test statistic. The p-value is the probability of obtaining a test statistic at least as extreme as the one that was observed, assuming that the null hypothesis is true.\n",
    "In confidence interval estimation, the CLT is used to calculate the confidence interval for a population parameter. The confidence interval is a range of values that is likely to contain the population parameter.\n",
    "In regression analysis, the CLT is used to calculate the standard errors of the regression coefficients. The standard errors of the regression coefficients are used to test the significance of the coefficients and to construct confidence intervals for the predicted values.\n",
    "The CLT is a powerful tool that can be used to make inferences about populations based on samples. It is essential for understanding many statistical concepts and techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766dd2ba-3949-4b5b-8989-f4abc15386d0",
   "metadata": {},
   "source": [
    "## Question 10 : State the assumptions of the Central Limit Theorem.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936fceb9-902d-49da-b011-e2e7e7851538",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) states that if we take a large number of samples from a population, the distribution of the sample means will be approximately normal, regardless of the shape of the population distribution. The CLT has four main assumptions:\n",
    "\n",
    "Random sampling: The samples must be randomly selected from the population. This means that each member of the population has an equal chance of being selected.\n",
    "\n",
    "Independent samples: The samples must be independent of each other. This means that the selection of one sample does not affect the selection of any other sample.\n",
    "\n",
    "Sufficient sample size: The sample size must be large enough for the CLT to apply. The exact sample size required depends on the shape of the population distribution.\n",
    "\n",
    "Continuous variable: The variable being measured must be continuous. This means that the variable can take on any value within a given range.\n",
    "\n",
    "If these assumptions are met, then the CLT can be used to make inferences about the population mean based on the sample mean. For example, we can use the CLT to construct confidence intervals for the population mean or to test hypotheses about the population mean.\n",
    "\n",
    "It is important to note that the CLT is a statistical theorem, and like all statistical theorems, it is based on probability. This means that there is a chance that the CLT will not apply in a particular situation. However, the CLT is a very powerful tool, and it can be used to make accurate inferences about the population mean in a wide variety of situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981c674f-69f6-4bb4-b7e1-ffd15dbc0c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
